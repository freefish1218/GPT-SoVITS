#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å†¥æƒ³éŸ³é¢‘ç”Ÿæˆä¸“ä¸šåº”ç”¨ - ä¿®å¤ç‰ˆ
"""

import os
import sys
import json
import warnings
import logging
import gradio as gr
import torch
import numpy as np

# è®¾ç½®æ—¥å¿—çº§åˆ«
logging.getLogger("markdown_it").setLevel(logging.ERROR)
logging.getLogger("urllib3").setLevel(logging.ERROR)
warnings.filterwarnings("ignore")

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ["version"] = "v2ProPlus"
os.environ["is_half"] = "True"

# æ·»åŠ è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# å¯¼å…¥å¿…è¦çš„æ¨¡å—
try:
    from config import get_weights_names, name2gpt_path, name2sovits_path
    SoVITS_names, GPT_names = get_weights_names()
    
    from GPT_SoVITS.inference_webui import (
        get_tts_wav,
        change_sovits_weights,
        change_gpt_weights,
        device,
        is_half,
        i18n,
        dict_language
    )
except ImportError as e:
    print(f"å¯¼å…¥é”™è¯¯ï¼š{e}")
    sys.exit(1)

# å†¥æƒ³åœºæ™¯é¢„è®¾é…ç½®
MEDITATION_PRESETS = {
    "å¹³é™èˆ’ç¼“": {
        "description": "é€‚åˆæ—¥å¸¸å†¥æƒ³ç»ƒä¹ ï¼Œå£°éŸ³æ¸©å’Œå¹³é™",
        "speed": 0.95,
        "top_k": 15,
        "top_p": 0.7,
        "temperature": 0.7,
        "pause_second": 0.4,
    },
    "æ·±åº¦æ”¾æ¾": {
        "description": "é€‚åˆæ·±åº¦æ”¾æ¾å’Œå‹åŠ›é‡Šæ”¾",
        "speed": 0.85,
        "top_k": 20,
        "top_p": 0.6,
        "temperature": 0.6,
        "pause_second": 0.5,
    },
    "æ­£å¿µè§‰å¯Ÿ": {
        "description": "é€‚åˆæ­£å¿µå†¥æƒ³å’Œè§‰å¯Ÿç»ƒä¹ ",
        "speed": 1.0,
        "top_k": 10,
        "top_p": 0.8,
        "temperature": 0.8,
        "pause_second": 0.35,
    },
    "ç¡çœ å¼•å¯¼": {
        "description": "é€‚åˆç¡å‰å†¥æƒ³å’ŒåŠ©çœ ",
        "speed": 0.8,
        "top_k": 25,
        "top_p": 0.5,
        "temperature": 0.5,
        "pause_second": 0.6,
    },
}

class MeditationApp:
    """å†¥æƒ³éŸ³é¢‘ç”Ÿæˆåº”ç”¨ç±»"""
    
    def __init__(self):
        self.current_preset = "å¹³é™èˆ’ç¼“"
        self.current_sovits = SoVITS_names[0] if SoVITS_names else None
        self.current_gpt = GPT_names[-1] if GPT_names else None
        print(f"åˆå§‹åŒ–å®Œæˆ: SoVITS={self.current_sovits}, GPT={self.current_gpt}")
    
    def generate_audio_simple(
        self,
        text,
        ref_audio,
        ref_text,
        preset_name,
        speed,
        top_k,
        top_p,
        temperature,
        pause_second,
        text_language,
        ref_language,
        how_to_cut,
        sovits_model,
        gpt_model
    ):
        """ç®€åŒ–çš„ç”Ÿæˆå‡½æ•°ï¼Œä¸ä½¿ç”¨progress"""
        print("\n" + "="*60)
        print("ç”ŸæˆéŸ³é¢‘è¢«è°ƒç”¨")
        print(f"æ–‡æœ¬: {text[:50] if text else 'None'}...")
        print(f"å‚è€ƒéŸ³é¢‘: {ref_audio}")
        print(f"å‚è€ƒæ–‡æœ¬: {ref_text}")
        print("="*60)
        
        # å‚æ•°éªŒè¯
        if not text:
            return gr.Warning("è¯·è¾“å…¥å†¥æƒ³å¼•å¯¼æ–‡æœ¬")
        
        if not ref_audio:
            return gr.Warning("è¯·ä¸Šä¼ å‚è€ƒéŸ³é¢‘")
        
        if not ref_text:
            return gr.Warning("è¯·è¾“å…¥å‚è€ƒéŸ³é¢‘çš„æ–‡æœ¬")
        
        try:
            # å¤„ç†MP3æ–‡ä»¶
            if isinstance(ref_audio, str) and ref_audio.lower().endswith('.mp3'):
                print("è½¬æ¢MP3ä¸ºWAV...")
                import librosa
                import soundfile as sf
                import tempfile
                
                audio_data, sr = librosa.load(ref_audio, sr=None)
                with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_wav:
                    wav_path = tmp_wav.name
                    sf.write(wav_path, audio_data, sr)
                    ref_audio = wav_path
                    print(f"å·²è½¬æ¢ä¸º: {wav_path}")
            
            # æ›´æ–°æ¨¡å‹
            if sovits_model and sovits_model != self.current_sovits:
                change_sovits_weights(sovits_model)
                self.current_sovits = sovits_model
            
            if gpt_model and gpt_model != self.current_gpt:
                change_gpt_weights(gpt_model)
                self.current_gpt = gpt_model
            
            print("è°ƒç”¨ get_tts_wav...")
            
            # ç”ŸæˆéŸ³é¢‘
            result_generator = get_tts_wav(
                ref_wav_path=ref_audio,
                prompt_text=ref_text,
                prompt_language=ref_language,
                text=text,
                text_language=text_language,
                how_to_cut=how_to_cut,
                top_k=top_k,
                top_p=top_p,
                temperature=temperature,
                ref_free=False,
                speed=speed,
                if_freeze=False,
                inp_refs=None,
                sample_steps=8,
                if_sr=False,
                pause_second=pause_second
            )
            
            # æ”¶é›†æ‰€æœ‰éŸ³é¢‘ç‰‡æ®µ
            audio_segments = []
            for sr, audio in result_generator:
                print(f"ç”Ÿæˆç‰‡æ®µ: sr={sr}, shape={audio.shape if hasattr(audio, 'shape') else 'N/A'}")
                audio_segments.append((sr, audio))
            
            if audio_segments:
                if len(audio_segments) == 1:
                    sr, audio = audio_segments[0]
                    print(f"ç”ŸæˆæˆåŠŸ! é‡‡æ ·ç‡={sr}")
                    return (sr, audio)
                else:
                    # åˆå¹¶å¤šä¸ªç‰‡æ®µ
                    sr = audio_segments[0][0]
                    all_audio = []
                    for seg_sr, seg_audio in audio_segments:
                        all_audio.append(seg_audio)
                    merged_audio = np.concatenate(all_audio)
                    print(f"åˆå¹¶ {len(audio_segments)} ä¸ªç‰‡æ®µæˆåŠŸ")
                    return (sr, merged_audio)
            else:
                print("æœªç”Ÿæˆä»»ä½•éŸ³é¢‘")
                return None
                
        except Exception as e:
            print(f"é”™è¯¯: {type(e).__name__}: {str(e)}")
            import traceback
            traceback.print_exc()
            return None

def create_interface():
    """åˆ›å»ºGradioç•Œé¢"""
    
    app_instance = MeditationApp()
    
    with gr.Blocks(title="å†¥æƒ³éŸ³é¢‘ç”Ÿæˆä¸“ä¸šç‰ˆ") as demo:
        
        gr.Markdown("# ğŸ§˜ å†¥æƒ³éŸ³é¢‘ç”Ÿæˆä¸“ä¸šç‰ˆ")
        gr.Markdown("ä½¿ç”¨å…ˆè¿›çš„AIæŠ€æœ¯ï¼Œä¸ºæ‚¨åˆ›é€ å®Œç¾çš„å†¥æƒ³å¼•å¯¼å£°éŸ³")
        
        with gr.Row():
            # å·¦ä¾§æ§åˆ¶é¢æ¿
            with gr.Column(scale=1):
                gr.Markdown("## ğŸ¯ å¿«é€Ÿé¢„è®¾")
                
                preset_selector = gr.Radio(
                    choices=list(MEDITATION_PRESETS.keys()),
                    value="å¹³é™èˆ’ç¼“",
                    label="é€‰æ‹©å†¥æƒ³åœºæ™¯"
                )
                
                # å‚æ•°è®¾ç½®
                with gr.Accordion("âš™ï¸ é«˜çº§å‚æ•°", open=False):
                    speed_slider = gr.Slider(0.6, 1.5, 0.95, step=0.05, label="è¯­é€Ÿ")
                    pause_slider = gr.Slider(0.1, 1.0, 0.4, step=0.05, label="å¥é—´åœé¡¿ï¼ˆç§’ï¼‰")
                    top_k_slider = gr.Slider(1, 50, 15, step=1, label="Top-K")
                    top_p_slider = gr.Slider(0.1, 1.0, 0.7, step=0.05, label="Top-P")
                    temperature_slider = gr.Slider(0.1, 1.0, 0.7, step=0.05, label="Temperature")
                
                # æ¨¡å‹é€‰æ‹©
                with gr.Accordion("ğŸ¤– æ¨¡å‹é€‰æ‹©", open=False):
                    sovits_dropdown = gr.Dropdown(
                        choices=SoVITS_names,
                        value=app_instance.current_sovits,
                        label="SoVITS æ¨¡å‹"
                    )
                    gpt_dropdown = gr.Dropdown(
                        choices=GPT_names,
                        value=app_instance.current_gpt,
                        label="GPT æ¨¡å‹"
                    )
            
            # å³ä¾§è¾“å…¥è¾“å‡º
            with gr.Column(scale=2):
                gr.Markdown("### ğŸ¤ å‚è€ƒéŸ³é¢‘è®¾ç½®")
                
                with gr.Row():
                    ref_audio_input = gr.Audio(
                        label="ä¸Šä¼ å‚è€ƒéŸ³é¢‘ï¼ˆ3-10ç§’ï¼‰",
                        type="filepath"
                    )
                    
                    with gr.Column():
                        ref_text_input = gr.Textbox(
                            label="å‚è€ƒéŸ³é¢‘æ–‡æœ¬",
                            placeholder="è¾“å…¥å‚è€ƒéŸ³é¢‘ä¸­è¯´çš„å†…å®¹...",
                            lines=2
                        )
                        ref_language = gr.Dropdown(
                            choices=list(dict_language.keys()),
                            value=i18n("ä¸­æ–‡"),
                            label="å‚è€ƒéŸ³é¢‘è¯­è¨€"
                        )
                
                gr.Markdown("### âœï¸ å†¥æƒ³å¼•å¯¼æ–‡æœ¬")
                
                text_input = gr.Textbox(
                    label="è¾“å…¥å†¥æƒ³å¼•å¯¼è¯",
                    placeholder="è¯·è¾“å…¥æ‚¨æƒ³è¦ç”Ÿæˆçš„å†¥æƒ³å¼•å¯¼æ–‡æœ¬...",
                    lines=5
                )
                
                with gr.Row():
                    text_language = gr.Dropdown(
                        choices=list(dict_language.keys()),
                        value=i18n("ä¸­æ–‡"),
                        label="æ–‡æœ¬è¯­è¨€"
                    )
                    cut_method = gr.Dropdown(
                        choices=[
                            i18n("ä¸åˆ‡"),
                            i18n("å‡‘å››å¥ä¸€åˆ‡"),
                            i18n("å‡‘50å­—ä¸€åˆ‡"),
                            i18n("æŒ‰ä¸­æ–‡å¥å·ã€‚åˆ‡"),
                            i18n("æŒ‰è‹±æ–‡å¥å·.åˆ‡"),
                            i18n("æŒ‰æ ‡ç‚¹ç¬¦å·åˆ‡"),
                        ],
                        value=i18n("æŒ‰ä¸­æ–‡å¥å·ã€‚åˆ‡"),
                        label="æ–‡æœ¬åˆ‡åˆ†æ–¹å¼"
                    )
                
                # ç”ŸæˆæŒ‰é’®
                generate_btn = gr.Button("ğŸµ ç”Ÿæˆå†¥æƒ³éŸ³é¢‘", variant="primary", size="lg")
                
                # è¾“å‡ºéŸ³é¢‘
                audio_output = gr.Audio(label="ç”Ÿæˆçš„å†¥æƒ³éŸ³é¢‘", type="numpy")
        
        # é¢„è®¾é€‰æ‹©äº‹ä»¶
        def update_preset(preset_name):
            preset = MEDITATION_PRESETS[preset_name]
            return (
                preset["speed"],
                preset["pause_second"],
                preset["top_k"],
                preset["top_p"],
                preset["temperature"]
            )
        
        preset_selector.change(
            fn=update_preset,
            inputs=[preset_selector],
            outputs=[speed_slider, pause_slider, top_k_slider, top_p_slider, temperature_slider]
        )
        
        # ç”ŸæˆæŒ‰é’®äº‹ä»¶ - ç›´æ¥ç»‘å®šï¼Œä¸ç”¨wrapper
        generate_btn.click(
            fn=app_instance.generate_audio_simple,
            inputs=[
                text_input,
                ref_audio_input,
                ref_text_input,
                preset_selector,
                speed_slider,
                top_k_slider,
                top_p_slider,
                temperature_slider,
                pause_slider,
                text_language,
                ref_language,
                cut_method,
                sovits_dropdown,
                gpt_dropdown
            ],
            outputs=[audio_output]
        )
    
    return demo

def main():
    """ä¸»å‡½æ•°"""
    demo = create_interface()
    demo.launch(
        server_name="0.0.0.0",
        server_port=9873,
        inbrowser=False,
        share=False,
        show_error=True
    )

if __name__ == "__main__":
    main()